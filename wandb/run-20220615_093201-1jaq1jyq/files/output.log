
train.py
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
instantiated sampler
instantiating dataloader
Some weights of the model checkpoint at openai/clip-vit-base-patch32 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.embeddings.position_embedding.weight', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.9.mlp.fc1.bias', 'logit_scale', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_projection.weight', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'visual_projection.weight', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.bias']
- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
tensor([[-0.8780, -0.0399, -0.8780,  1.9576,  1.4372, -0.3345, -0.8780,  0.1308,
         -0.8780,  1.2865, -0.8780,  0.8306, -0.8780],
        [-0.8375,  0.5699, -0.8375,  1.9594,  1.4198, -0.8375, -0.8375, -0.1489,
         -0.8375,  1.1173,  0.8705, -0.7634, -0.8375]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 3], device='cuda:0')
tensor([[-0.8240,  0.5110, -0.8240,  1.7035,  0.6392, -0.8240, -0.8240,  0.4903,
         -0.8240,  2.0769, -0.8240,  0.3470, -0.8240],
        [-1.0308,  0.7111, -1.0308,  1.1310,  1.5562, -0.3905, -1.0308,  0.1313,
         -1.0308,  1.7719,  0.3868, -0.1435, -1.0308]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 9], device='cuda:0')
tensor([[-1.0621,  0.3818, -1.0621,  0.9778,  1.7100, -1.0621, -0.7469,  1.1271,
         -1.0621,  0.8822, -1.0621,  0.8388,  0.1400],
        [-1.0213,  0.2440, -1.0213,  0.5499,  2.3251, -0.4603, -1.0213,  0.3132,
         -1.0213,  1.0223,  0.7008,  0.4114, -1.0213]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.6991,  0.5256, -0.6991,  2.0904,  1.6824, -0.6991, -0.6991,  0.0254,
         -0.6991,  1.2695, -0.6991, -0.6991, -0.6991],
        [-0.7821, -0.6596, -0.7821,  0.5979,  2.3877, -0.7821, -0.7821,  0.1538,
         -0.7821,  1.3171, -0.6093,  1.0880, -0.3652]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 4], device='cuda:0')
tensor([[-0.8189,  1.2595, -0.8189,  0.8004,  1.7618, -0.8189, -0.8189,  0.3789,
         -0.8189,  1.7096, -0.2965, -0.7004, -0.8189],
        [-0.6411, -0.6411, -0.6411,  2.3843,  1.8267,  0.1239, -0.6411, -0.5917,
         -0.6411,  0.8503, -0.6411, -0.1059, -0.6411]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 3], device='cuda:0')
tensor([[-0.8784,  1.7421, -0.8784,  0.8570,  1.2337, -0.8784, -0.8784,  0.2771,
          0.3337,  1.5448, -0.8784, -0.7992, -0.7968],
        [-0.7247,  1.0286, -0.7247,  1.0579,  2.3930, -0.7247, -0.7247, -0.7247,
          0.5489,  0.7694, -0.7247, -0.7247, -0.7247]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([1, 4], device='cuda:0')
tensor([[-0.7123,  0.1359, -0.7123,  1.9451,  2.0645, -0.7123, -0.7123,  0.3346,
         -0.7123,  1.0092, -0.5032, -0.7123, -0.7123],
        [-0.9646, -0.0057, -0.9646,  0.6580,  1.6479,  0.3324, -0.2775, -0.9646,
         -0.9646,  2.2317,  0.1469,  0.0893, -0.9646]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.7275,  1.5001, -0.7275,  1.6201,  2.1289, -0.7275, -0.6097,  0.0287,
         -0.7275, -0.7275, -0.7061, -0.2661, -0.0584],
        [-0.8626,  0.8493, -0.8626,  1.2796,  1.9570, -0.7963, -0.8626,  0.5691,
         -0.8626,  1.1689, -0.8626,  0.1482, -0.8626]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.9508,  1.4180, -0.9508,  1.0239,  1.9550, -0.9508, -0.9265, -0.5959,
         -0.8275,  1.1981, -0.0441, -0.2420, -0.1066],
        [-0.8883, -0.6345, -0.8883,  1.2430,  2.4004,  0.5579, -0.8883,  0.6310,
         -0.8883,  0.7203, -0.2041, -0.2724, -0.8883]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.6857, -0.0044, -0.6857,  2.0197,  1.7090, -0.6857, -0.6857, -0.5755,
         -0.6857,  1.5373, -0.6857,  0.1136, -0.6857],
        [-0.6452,  0.4787, -0.6452,  2.5690,  1.3451, -0.6452, -0.6452, -0.6452,
         -0.6452,  0.9906, -0.6452, -0.2219, -0.6452]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 3], device='cuda:0')
tensor([[-0.6326, -0.1302, -0.6326,  2.2886,  2.2081, -0.5996, -0.6326,  0.1311,
         -0.6326,  0.1552, -0.6326, -0.2578, -0.6326],
        [-0.9187,  0.4169, -0.9187,  1.4645,  1.9365, -0.9187, -0.9187,  0.5710,
         -0.9187,  1.1689, -0.3166,  0.2712, -0.9187]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 4], device='cuda:0')
tensor([[-0.7456, -0.7456, -0.7456,  2.2097,  1.6223, -0.7456, -0.7456, -0.7456,
         -0.7456,  0.6912, -0.5596,  0.5488,  0.7071],
        [-0.7510, -0.6053, -0.7510,  0.0739,  2.4803, -0.7510, -0.7510,  0.2068,
         -0.3797,  1.5825, -0.7510,  0.8635, -0.4668]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 4], device='cuda:0')
/home/aneesh/github/slot_vqa/train.py:303: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)
tensor([[-0.9387,  0.9499, -0.9387,  1.4710,  1.8072, -0.9387, -0.6878, -0.0756,
         -0.9387,  1.3313, -0.0927, -0.0097, -0.9387],
        [-0.7838,  1.3151, -0.7838,  0.6460,  2.2842, -0.7838, -0.7838, -0.1458,
         -0.7838,  1.2755, -0.5299, -0.1423, -0.7838]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.7272,  0.9988, -0.7272,  0.8875,  2.7525, -0.7272, -0.7272, -0.4183,
         -0.3655,  0.3688, -0.7272,  0.1396, -0.7272],
        [-0.8486,  0.6502, -0.8486,  1.3333,  1.8442, -0.3470, -0.7863, -0.4976,
         -0.8486,  1.8220, -0.2227, -0.8486, -0.4016]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.6708, -0.0784, -0.6708,  1.6209,  0.7595, -0.6708, -0.5813, -0.5211,
         -0.6708,  2.5281, -0.6708,  0.2970, -0.6708],
        [-0.8865,  0.5090, -0.8865,  1.6309,  1.7584, -0.8865, -0.8865,  0.3428,
         -0.8865,  1.3163, -0.8865,  0.3248, -0.5633]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.7713,  1.8390, -0.7713,  0.8659,  1.2848, -0.7713, -0.7713, -0.7713,
         -0.7713,  1.2892, -0.7713,  0.8915, -0.7713],
        [-0.7153,  0.1513, -0.7153,  1.4554,  2.6164, -0.6313, -0.7153,  0.2991,
         -0.7153,  0.6326, -0.7153, -0.2317, -0.7153]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([1, 4], device='cuda:0')
tensor([[-0.8376, -0.1621, -0.8376,  2.4272,  1.6054, -0.2541, -0.8376, -0.8376,
         -0.8376, -0.3794,  0.1268,  0.8758, -0.0516],
        [-0.6735,  0.3614, -0.6735,  0.4242,  2.2571, -0.6735, -0.6735, -0.3489,
         -0.6735,  2.0929, -0.5875, -0.1580, -0.6735]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 4], device='cuda:0')
tensor([[-0.9719,  0.2884, -0.9719,  0.8229,  1.7212, -0.4484, -0.4779, -0.3436,
         -0.9719,  1.9597, -0.5394,  0.9048, -0.9719],
        [-0.8519,  0.0502, -0.8519,  0.5082,  2.5981, -0.1028, -0.8519, -0.1660,
          0.4514,  1.3804, -0.8519, -0.4601, -0.8519]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.8289,  0.8309, -0.8289,  1.2632,  1.6993, -0.2530, -0.8289, -0.7235,
         -0.8289,  1.7071, -0.8289,  0.4493, -0.8289],
        [-0.7333,  1.1881, -0.7333,  0.4527,  2.4265, -0.6821, -0.7333,  1.0779,
         -0.7333,  0.5335, -0.5969, -0.7333, -0.7333]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.7789,  1.1455, -0.7789,  1.3733,  1.2530, -0.3692, -0.7789, -0.5727,
         -0.7789,  2.0232, -0.7789, -0.7789, -0.1797],
        [-0.6794,  1.7093, -0.6794,  0.7229,  1.9959, -0.6794, -0.6794, -0.6794,
         -0.6794,  1.3482, -0.4913, -0.6794, -0.5290]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.7322,  1.6560, -0.7322,  0.8567,  2.1700, -0.6364, -0.7322, -0.7322,
         -0.7322,  1.0159, -0.3008, -0.5446, -0.5557],
        [-0.6508,  1.7518, -0.6508,  1.4447,  2.1111, -0.6508, -0.6508, -0.6508,
         -0.5091,  0.1344, -0.6508, -0.3770, -0.6508]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.5891, -0.5891, -0.5891,  0.1899,  2.5747, -0.5891, -0.5891,  0.3985,
         -0.5891,  1.8232, -0.2734, -0.5891, -0.5891],
        [-0.8046,  0.4659, -0.8046,  2.0325,  1.8855,  0.5790, -0.8046, -0.2714,
         -0.8046,  0.6981, -0.8046, -0.8046, -0.5621]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 3], device='cuda:0')
tensor([[-0.6680,  0.4870, -0.6680,  1.9367,  2.2384, -0.4380, -0.6680, -0.6680,
         -0.6680,  0.7658, -0.6680, -0.3138, -0.6680],
        [-0.7485, -0.2088, -0.7485,  0.4145,  0.9081, -0.7485, -0.7485,  0.8768,
         -0.7485,  2.7785, -0.7485,  0.0484, -0.3267]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.7599,  0.9461, -0.7599,  0.8782,  1.9155, -0.6767, -0.7599,  0.5722,
         -0.7599,  1.6840, -0.7599, -0.7599, -0.7599],
        [-0.7083,  1.0806, -0.7083,  0.6074,  2.3312, -0.7083, -0.7083, -0.4615,
         -0.7083,  1.5135, -0.7083, -0.1133, -0.7083]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.7141,  1.8124, -0.7141,  2.1250,  1.0947, -0.5395, -0.7141, -0.3220,
         -0.7141,  0.5765, -0.7141, -0.7141, -0.4622],
        [-0.8239,  1.5574, -0.8239,  1.0661,  1.5200, -0.8239, -0.8239, -0.8239,
         -0.8239,  1.5397,  0.0559,  0.0282, -0.8239]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 1], device='cuda:0')
tensor([[-0.9652,  0.3010, -0.9652,  0.7209,  1.5497, -0.9652, -0.9652,  0.7209,
         -0.9652,  1.8679,  0.6230,  0.0081, -0.9652],
        [-0.8106,  1.0080, -0.8106,  1.7399,  0.6585, -0.8106,  1.3536, -0.8106,
         -0.8106,  1.3713, -0.8106, -0.8106, -0.4574]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 3], device='cuda:0')
tensor([[-0.8432,  0.2876, -0.8432,  1.1240,  2.4096, -0.8432, -0.8432,  0.1506,
         -0.8432,  1.2143, -0.8432, -0.2569,  0.1301],
        [-0.8286,  1.5525, -0.8286,  0.5575,  2.1625, -0.8286, -0.8286, -0.0364,
         -0.8286,  0.8586,  0.5451, -0.6682, -0.8286]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.7062, -0.5821, -0.7062,  2.4587,  1.5989, -0.7062, -0.7062, -0.3054,
         -0.7062,  0.8684, -0.6304,  0.4563, -0.3333],
        [-0.9687,  0.6864, -0.9687,  1.1648,  2.0162, -0.9687, -0.9687,  0.2478,
         -0.9687,  1.0925,  0.1657,  0.4392, -0.9687]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 4], device='cuda:0')
tensor([[-0.8077,  0.6462, -0.8077,  1.2697,  2.3201,  1.0269, -0.8077, -0.8077,
         -0.8077,  0.4384, -0.6009, -0.2543, -0.8077],
        [-0.5753,  2.2343, -0.5753, -0.0138,  2.2332, -0.5753, -0.5753, -0.5753,
         -0.3507,  0.4991, -0.5753, -0.5753, -0.5753]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 1], device='cuda:0')
tensor([[-0.8882, -0.2742, -0.8882,  1.5982,  0.9877, -0.8882, -0.8882,  0.0102,
         -0.8882,  2.2334, -0.2534,  0.5099, -0.3708],
        [-0.8785,  0.8674, -0.8785,  1.0527,  1.8875, -0.8785, -0.8785, -0.1437,
         -0.8785,  1.3757, -0.8785,  0.8247, -0.5933]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.8273,  1.3400, -0.8273,  1.1508,  1.2433, -0.8273, -0.8273, -0.8273,
         -0.8273,  1.9684, -0.4104,  0.0913, -0.4198],
        [-0.8318,  1.3395, -0.8318,  1.1575,  1.6611, -0.0628, -0.8318,  0.2450,
         -0.8318,  1.4826, -0.8318, -0.8318, -0.8318]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.7742,  0.6530, -0.7742,  2.0649,  1.4392, -0.7742, -0.7742, -0.0356,
         -0.7742,  1.4231, -0.7742, -0.1254, -0.7742],
        [-0.7680,  1.2339, -0.7680,  0.9946,  2.1672, -0.7680, -0.7680, -0.6384,
         -0.5211,  1.2480, -0.7680,  0.1238, -0.7680]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 4], device='cuda:0')
tensor([[-0.6568,  0.2839, -0.6568,  0.7089,  2.1691, -0.6568, -0.6568, -0.6119,
         -0.4975,  2.1281, -0.6568, -0.4524, -0.4442],
        [-0.9035,  1.0153, -0.9035,  0.8436,  2.3681, -0.4497, -0.9035, -0.2177,
         -0.9035,  0.9838, -0.9035,  0.4050, -0.4308]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8878,  1.1300, -0.8878,  1.1273,  1.7923, -0.1428, -0.8878, -0.8670,
         -0.8878,  1.3816, -0.5464,  0.5641, -0.8878],
        [-0.9495,  0.4950, -0.9495,  1.6367,  1.6040, -0.9495, -0.9495,  0.2097,
         -0.9495,  1.3265,  0.5282, -0.1032, -0.9495]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 3], device='cuda:0')
tensor([[-0.5885, -0.5885, -0.5885,  0.9099,  1.4315, -0.5885, -0.5885, -0.0947,
         -0.5885,  2.6990, -0.5885, -0.2374, -0.5885],
        [-0.9766,  1.8313, -0.9766,  0.8180,  2.0335, -0.9766, -0.4153, -0.5678,
          0.0757,  0.1343, -0.6218, -0.8893,  0.5313]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.6053, -0.6053, -0.6053,  0.3122,  2.7666, -0.6053, -0.6053, -0.6053,
         -0.6053,  1.4601,  0.4144, -0.1105, -0.6053],
        [-0.7239, -0.7239, -0.7239,  0.4841,  2.5759, -0.7239, -0.7239,  0.8358,
         -0.7239,  0.9110, -0.5403,  0.8005, -0.7239]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8037,  2.1521, -0.8037,  1.2612,  0.5424, -0.8037, -0.8037, -0.8037,
         -0.8037,  1.2122,  0.6681, -0.2102, -0.8037],
        [-0.7253,  0.1356, -0.7253,  1.0135,  2.5657, -0.7253, -0.7253,  0.1441,
         -0.7253,  1.2894, -0.0713, -0.7253, -0.7253]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([1, 4], device='cuda:0')
tensor([[-0.7578,  0.1924, -0.7578,  0.3152,  1.5257, -0.0413, -0.5013, -0.7578,
         -0.7578,  2.6130, -0.7578,  0.3588, -0.6734],
        [-0.9712,  1.2325, -0.9712,  0.5435,  1.4895, -0.9712, -0.9712,  0.8267,
         -0.9712,  1.5780,  0.3240, -0.1671, -0.9712]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 9], device='cuda:0')
tensor([[-0.7400,  0.6023, -0.7400,  2.0205,  1.6937, -0.7400, -0.7400, -0.7400,
         -0.7400,  1.2232, -0.5614,  0.2015, -0.7400],
        [-0.8913,  0.2173, -0.8913,  1.1302,  1.5220, -0.8913, -0.8913,  0.9273,
         -0.8913,  1.9032, -0.3302, -0.0217, -0.8913]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 9], device='cuda:0')
tensor([[-0.6693,  0.8574, -0.6693,  0.8751,  2.5320, -0.5932, -0.6693, -0.2295,
         -0.6693,  1.2434, -0.6693, -0.6693, -0.6693],
        [-0.8995, -0.2968, -0.8995,  0.4793,  2.4234, -0.8995, -0.5431,  0.1613,
         -0.8995,  1.4333,  0.2886,  0.5517, -0.8995]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8384, -0.4454, -0.8384,  0.9716,  1.6367, -0.8384, -0.8384,  0.2494,
         -0.8384,  2.2153, -0.6685, -0.2149,  0.4480],
        [-0.7598,  0.2278, -0.7598,  1.3065,  1.8521, -0.7598, -0.7598, -0.6675,
         -0.7598,  1.5791, -0.7598,  0.9589, -0.6981]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.6843,  0.0137, -0.6843,  1.6425,  2.2129, -0.6843, -0.6843,  0.3733,
         -0.6843,  1.2321, -0.6843, -0.6843, -0.6843],
        [-0.8183,  2.0185, -0.8183,  0.8344,  1.1262,  0.4521, -0.8183, -0.7427,
         -0.8183,  1.4592, -0.8183, -0.2377, -0.8183]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 1], device='cuda:0')
tensor([[-9.0694e-01, -1.1333e-03, -9.0694e-01,  1.1840e+00,  1.7042e+00,
         -9.0694e-01, -9.0694e-01, -4.5843e-01, -9.0694e-01,  5.2729e-01,
          1.5427e+00,  9.4298e-01, -9.0694e-01],
        [-7.9788e-01,  1.2502e+00, -7.9788e-01,  1.0548e+00,  1.6323e+00,
         -7.5657e-01, -7.9788e-01, -7.9788e-01, -7.9788e-01,  1.6634e+00,
         -7.9788e-01,  4.7083e-01, -5.2772e-01]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.7326,  0.8951, -0.7326,  0.9712,  2.5736, -0.0561, -0.7326, -0.3975,
         -0.5589,  0.9683, -0.7326, -0.7326, -0.7326],
        [-0.8272,  0.8096, -0.8272,  1.2778,  2.3380, -0.8272, -0.8272,  0.1757,
         -0.8272,  0.9556, -0.8272, -0.3927, -0.2009]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8206,  1.3141, -0.8206,  1.3442,  1.4880,  0.9620, -0.8206, -0.8160,
         -0.8206,  1.1584, -0.8206, -0.5271, -0.8206],
        [-0.9028,  0.6250, -0.9028,  1.6001,  2.1650, -0.9028, -0.9028,  0.0990,
          0.2066,  0.7893, -0.9028, -0.2222, -0.7491]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8620,  0.6587, -0.8620,  1.1586,  2.1285, -0.8620, -0.8620,  0.3168,
         -0.8620,  1.4666, -0.6628, -0.3685, -0.3876],
        [-0.8194,  0.1634, -0.8194,  1.8581,  1.1264, -0.1170, -0.8194, -0.2342,
         -0.8194,  2.0365, -0.8194,  0.0834, -0.8194]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.7368,  1.3577, -0.7368,  2.1511,  1.3668, -0.7368, -0.7368, -0.7368,
         -0.6483,  0.4050, -0.7368,  0.5255, -0.7368],
        [-0.7129, -0.1861, -0.7129,  2.9506,  0.9537, -0.7129, -0.7129,  0.3387,
         -0.4332,  0.5121, -0.4854, -0.0860, -0.7129]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 3], device='cuda:0')
tensor([[-0.6780,  0.2035, -0.6780,  2.6900,  0.8233, -0.5266, -0.6780,  0.3665,
         -0.6780,  1.1892, -0.6780, -0.6780, -0.6780],
        [-0.7159,  0.0864, -0.7159,  0.7148,  1.5948, -0.7159, -0.6547,  1.0987,
         -0.7159,  2.1711, -0.7159, -0.7159, -0.7159]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([3, 9], device='cuda:0')
tensor([[-0.8627,  0.3082, -0.8627,  0.8622,  2.5348, -0.8627, -0.8627,  0.6527,
         -0.8627,  0.9332, -0.8084,  0.0729, -0.2419],
        [-0.7856,  0.5080, -0.7856,  1.7963,  1.5333, -0.7856, -0.7856,  0.7084,
         -0.7448,  1.4531, -0.7856, -0.5410, -0.7856]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 3], device='cuda:0')
tensor([[-0.9801,  0.9906, -0.9801,  1.3718,  1.6376, -0.9801, -0.9801,  0.3566,
         -0.9801,  0.9238,  0.8149, -0.2149, -0.9801],
        [-0.7489,  1.9094, -0.7489,  1.1437,  1.7846, -0.7489, -0.7489,  0.0064,
         -0.4544,  0.8529, -0.7489, -0.7489, -0.7489]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 1], device='cuda:0')
tensor([[-0.6194, -0.2403, -0.6194,  1.9747,  1.1131, -0.6194, -0.6194, -0.0665,
         -0.6194,  2.1742, -0.6194, -0.6194, -0.6194],
        [-0.8085,  0.3286, -0.8085,  1.5214,  2.2042, -0.8085, -0.8085, -0.1007,
         -0.8085,  1.1161, -0.8085,  0.3988, -0.6175]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([9, 4], device='cuda:0')
tensor([[-0.6834,  0.5729, -0.6834,  1.6709,  2.3535, -0.6834, -0.6834, -0.6834,
         -0.1665,  0.8805, -0.6834, -0.5868, -0.6242],
        [-0.9604,  0.8857, -0.9604,  0.9398,  1.1579,  0.1383, -0.9604, -0.9604,
         -0.9604,  2.0081, -0.0034,  0.6361, -0.9604]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.6348,  0.3584, -0.6348,  1.2066,  2.1131, -0.6348, -0.6348, -0.6348,
         -0.4829,  1.8724, -0.6348, -0.6242, -0.6348],
        [-0.8675,  0.3782, -0.8675,  1.8273,  1.3677, -0.8675, -0.8675,  0.4245,
         -0.8675,  1.1888, -0.8675,  0.8860, -0.8675]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 3], device='cuda:0')
tensor([[-0.8661,  0.4294, -0.8661,  1.4225,  2.4548, -0.6650, -0.8661, -0.0723,
         -0.8661, -0.1114,  0.7308,  0.1417, -0.8661],
        [-0.6664, -0.1024, -0.6664,  0.3724,  2.6245,  0.2086, -0.5616, -0.6664,
         -0.2402,  1.6973, -0.6664, -0.6664, -0.6664]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8116,  0.9063, -0.8116,  0.0557,  2.0119, -0.8116, -0.8116, -0.1504,
         -0.8116,  1.9574,  0.4421, -0.3531, -0.8116],
        [-0.7610, -0.3548, -0.7610,  1.7275,  1.4455, -0.4582, -0.7610,  0.0084,
         -0.7610,  2.0207, -0.7610,  0.1771, -0.7610]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.6591,  1.8436, -0.6591,  0.5695,  2.2211, -0.2570, -0.6591, -0.6591,
         -0.6591,  0.8951, -0.6591, -0.6591, -0.6591],
        [-0.5762,  0.6223, -0.5762,  0.0829,  2.8374, -0.5762, -0.5762, -0.2959,
         -0.5762,  1.3507, -0.5762, -0.5641, -0.5762]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 4], device='cuda:0')
tensor([[-0.8886,  1.8806, -0.8886,  0.8326,  1.4640, -0.8886, -0.8886, -0.8886,
         -0.8886,  1.2350, -0.1377,  0.4421, -0.3848],
        [-0.7544,  1.5496, -0.7544,  0.4985,  1.9892, -0.7544, -0.6145, -0.5673,
         -0.7544,  1.4996,  0.1712, -0.7544, -0.7544]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([1, 4], device='cuda:0')
tensor([[-0.9670,  0.5920, -0.9670,  1.0289,  2.4589, -0.9670, -0.9670,  0.1611,
         -0.9670,  0.1880,  0.5046, -0.5725,  0.4739],
        [-0.9343, -0.0174, -0.9343,  1.9275,  1.5565, -0.9003, -0.9343,  0.3753,
         -0.9343,  0.7263, -0.3735,  1.1305, -0.6874]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 3], device='cuda:0')
tensor([[-0.6764,  1.6103, -0.6764,  1.5889,  2.0156, -0.6764, -0.6764, -0.6764,
         -0.6764,  0.3612, -0.1647, -0.6764, -0.6764],
        [-0.8320,  0.2311, -0.8320,  1.3018,  1.7293, -0.8320, -0.8320,  0.4348,
         -0.8320,  1.7576, -0.8320,  0.3695, -0.8320]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
tensor([4, 9], device='cuda:0')
tensor([[-0.6487,  1.6369, -0.6487,  2.0465,  1.4294, -0.6487, -0.6487, -0.6487,
         -0.5605,  0.6370, -0.6487, -0.6487, -0.6487],
        [-0.8523,  0.6123, -0.8523,  1.7112,  1.7392, -0.8523, -0.8523, -0.4832,
         -0.8523,  1.4344,  0.1411, -0.0412, -0.8523]], device='cuda:0',
       grad_fn=<_DDPSinkBackward>)
